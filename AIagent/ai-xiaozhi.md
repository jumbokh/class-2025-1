

---

## 第 1 頁：封面

### 投影片內容（PPT）

**AI語音小助理（小智）實驗**
ESP32-S3 語音 × IoT 應用

* 麥克風輸入與語音播放
* Function Calling 控制硬體
* 結合 MQTT / LINE / Google Sheet

授課教師：__________
課程名稱：__________
日期：__________

### 講稿示意

「今天這堂課我們要玩的是 *真正會講話、能控制硬體* 的 AI 語音小助理，也就是『小智』。
整套系統是基於 ESP32-S3 這顆晶片，再加上麥克風、喇叭、繼電器、感測器，外加雲端 AI 和 IoT 服務。

接下來幾個實驗，我會帶大家從：

1. 把板子連上網路、綁定後臺；
2. 確認語音輸入與播放正常；
3. 用語音控制 LED、繼電器；
4. 最後再把語音接到 MQTT 或 LINE、Google Sheet。

希望大家上完可以說：『我做過一個會講話又會控制東西的 AI 助理。』」

### 板書建議

* AI 語音小助理 = ESP32-S3 + 麥克風 + 喇叭 + 雲端 AI + IoT
* 關鍵字：**語音控制、Function Calling、MQTT**

### 提問引導

* 「有沒有人用過智慧音箱？像是小愛同學、Google Home？
  你們印象最深的一個功能是什麼？」

---

## 第 2 頁：課程目標與學習重點

### 投影片內容

**學習目標**

* 了解「小智」系統架構
* 能讀懂麥克風 / 喇叭接線
* 熟悉 Xizahi.me 後臺設定流程
* 理解 Function Calling 概念
* 初步使用 IoT 擴充（MQTT / LINE / Google Sheet）

### 講稿示意

「這堂課我們不是只看程式，而是整套系統一起看。
今天的學習重點有五個：

1. 先弄懂小智整體架構，知道語音從『講出口』到『硬體動作』中間經過哪些步驟；
2. 學會麥克風 INMP441 和喇叭擴大機 MAX98357A 的接線位置；
3. 認識 Xizahi.me 後臺，知道在哪裡設定角色、聲紋、查看歷史紀錄；
4. 理解什麼是 Function Calling —— AI 語音助理怎麼轉成『呼叫某個硬體工具』；
5. 最後看一下 IoT 擴充：把它接到 MQTT、LINE 或 Google Sheet。

你們不一定一次全做完，但至少要能說得出來『整條資料流怎麼走』。」

### 板書建議

寫一列：

* 目標：**看架構 → 接線 → 後臺 → Function Calling → IoT**

### 提問引導

* 「你們覺得，在這五個目標裡，自己對哪一塊最不熟？硬體？語音？還是 MQTT / LINE？」

---

## 第 3 頁：小智專案概觀

### 投影片內容

* 核心晶片：**ESP32-S3 N16R8**
* 支援 44 pins（樂鑫版）、40/42 pins（S3-Cam / 果云版）
* 內建 Wi-Fi / BLE，適合語音 + IoT
* 結合雲端大模型與 Function Calling Workflow

### 講稿示意

「小智的核心是一顆 ESP32-S3 N16R8，
N16 代表 16MB Flash，R8 代表 8MB PSRAM，很適合做語音與 AI 相關應用。

板子有不同的版本，有 44 pins 的樂鑫版，也有 40 或 42 pins 的 S3-Cam / 果云版，
你們實驗桌上的是 XX 版本（老師依實際情況補充）。

ESP32-S3 最大的優點是：

* 內建 Wi-Fi，可以直接連網；
* 內建 BLE，之後還可以跟手機、感測器互動；
* 外加 PSRAM，可以處理比較大的語音 Buffer。

而小智背後接的是雲端大模型，透過 Function Calling 讓 AI 幫我們決定要呼叫哪個『工具』來 control LED、Relay 或 MQTT。」

### 板書建議

* ESP32-S3 N16R8

  * Wi-Fi / BLE
  * 16MB Flash, 8MB PSRAM
  * 語音 + IoT

### 提問引導

* 「為什麼語音系統會需要比較多的記憶體（像 PSRAM）？你們猜原因是什麼？」

---

## 第 4 頁：系統整體架構圖

### 投影片內容

（放架構圖＋簡短文字）

* INMP441 → I2S → ESP32-S3
* ESP32-S3 → 雲端（語音辨識 / LLM）
* 雲端 → Function Calling → JSON 指令
* 本地 MCP Tool 控制硬體模組
* IoT Tool 連接 MQTT / LINE / Google Sheet

### 講稿示意

「這張圖是我們整個系統的『鳥瞰圖』。

1. 左邊是 INMP441 麥克風，它是 I2S 介面，負責把聲音轉成數位訊號；
2. 中間的 ESP32-S3 收到音訊後，會做一些前處理，然後送到雲端，讓語音識別和大模型來理解你講的話；
3. 大模型理解後，會決定要不要呼叫某個 Tool，例如 LED Tool、Relay Tool、MQTT Tool；
4. 雲端回來的是 JSON 指令，ESP32-S3 解析後，就透過 MCP Tool 控制對應的 GPIO 或發 MQTT、LINE。

把這張圖記在腦中，後面所有實驗都在走這條路線。」

### 板書建議

畫簡圖：

* 語音 → 麥克風 → ESP32-S3 → 雲端 AI → JSON → MCP Tool → LED / Relay / MQTT

### 提問引導

* 「你們覺得哪一段最容易出問題？是硬體接線、網路、還是雲端服務？」

---

## 第 5 頁：硬體：ESP32-S3 開發板與擴充板

### 投影片內容

* ESP32-S3 N16R8 開發板結構
* 擴充板 BK-IO 命名規則

  * BK-IOx_S：訊號腳
  * BK-IOx_3V3：3.3V 電源
  * BK-IOx_GND：接地
* 44 pins / 40 pins 差異簡述

### 講稿示意

「實作時，最常出錯的不是程式，而是『腳位接錯』。

我們的擴充板把腳位都命名成 BK-IOx，後面再加後綴：

* `_S` 代表 Signal；
* `_3V3` 代表 3.3V 電源；
* `_GND` 代表接地。

所以你看到 BK-IO18_S，就知道那是第 18 號訊號腳；
BK-IO18_3V3 就是那個區域的 3.3V；BK-IO18_GND 就是附近的 GND。

不同版本的板子，實際對應 GPIO 可能稍有不同，所以 **一定要對照資料表**，不要用猜的。」

### 板書建議

* BK-IOx_S → Signal
* BK-IOx_3V3 → Power
* BK-IOx_GND → GND

### 提問引導

* 「有沒有人之前在接 ESP32 或 Arduino 時，遇過『燒焦味』或 IC 過熱？
  你覺得最可能是什麼原因？」

---

## 第 6 頁：INMP441 麥克風接線說明

### 投影片內容

**INMP441 → ESP32-S3 擴充板**

* GND → BK-IO6_GND / BK-GND
* VDD/3V3 → BK-IO6_3V3 / BK-3V3
* WS → BK-IO4_S / BK-G1
* SCK → BK-IO5_S / BK-G2
* SD → BK-IO6_S / BK-G42

關鍵訊號：**WS、SCK、SD**

### 講稿示意

「INMP441 是一顆 I2S 麥克風，接線有幾個關鍵：

* GND 和 VDD 很直觀，一定要接對；
* I2S 的三個訊號：WS（Word Select）、SCK（Serial Clock）、SD（Serial Data）。

WS 負責『現在是左聲道還是右聲道』、
SCK 是時鐘、
SD 是實際的音訊資料。

我們擴充板已經幫你規劃好：
WS → BK-IO4_S，SCK → BK-IO5_S，SD → BK-IO6_S。
你們實作時，先對照講義，再一步一步插線。」

### 板書建議

寫：

* INMP441：WS / SCK / SD
* WS → 「哪一個 Channel」
* SCK → Clock
* SD → Data

### 提問引導

* 「如果 WS 或 SCK 接錯，你覺得會發生什麼現象？完全沒聲音？還是雜訊很多？」

---

## 第 7 頁：MAX98357A 語音輸出與喇叭

### 投影片內容

**MAX98357A → ESP32-S3 擴充板**

* Vin → BK-IO16_3V3 或 BK-5V（注意勿接反）
* GND → BK-IO16_GND / BK-GND
* DIN → BK-IO7_S / BK-G39
* BCLK → BK-IO15_S / BK-G40
* LRC → BK-IO16_S / BK-G41

喇叭：紅線 → ⊕，黑線 → ⊖

### 講稿示意

「MAX98357A 是一顆『I2S DAC + 擴大機』，
前面我們說 INMP441 用 I2S 把聲音送進來，
這一顆是用 I2S 把數位聲音轉成類比輸出給喇叭。

接線重點：

* Vin 和 GND 千萬不能接反，不然有機會燒掉模組；
* DIN、BCLK、LRC 一樣是 I2S 三要素：

  * DIN：Data In；
  * BCLK：Bit Clock；
  * LRC：Left/Right Clock。

喇叭紅線接 ⊕，黑線接 ⊖，接反不會馬上燒掉，但聲音可能怪怪的。」

### 板書建議

* MAX98357A：DIN / BCLK / LRC
* 注意：**Vin / GND 不可接反**

### 提問引導

* 「同樣是 I2S，為什麼麥克風跟擴大機可以共用一組 I2S 匯流排？你們覺得有什麼好處？」

---

## 第 8 頁：其他擴充模組總覽（MCP Tool）

### 投影片內容

**常用模組接線示例（BK-IO）**

* LED：BK-IO18_S / 3.3V / GND
* Relay：BK-IO8_S / 3.3V / GND
* Buzzer：BK-IO3_S / GND
* Servo：BK-IO10_S / 3.3V / GND
* DHT11：BK-IO9_S / 3.3V / GND

透過 **MCP Tool** 統一註冊與控制

### 講稿示意

「除了麥克風和喇叭，小智還可以連很多模組。
現在我們先記住幾個典型接法：

* LED 用 BK-IO18；
* Relay 用 BK-IO8；
* Buzzer 用 BK-IO3；
* Servo 用 BK-IO10；
* DHT11 用 BK-IO9。

在程式裡，我們不會直接到處 `digitalWrite(18, HIGH)`，
而是透過 MCP Tool 把這些模組抽象成一顆一顆『工具』，
例如 `tool = "led"`、`action = "on"`，
這樣雲端下來的 JSON 就可以統一處理。」

### 板書建議

畫一個簡表：

* LED → IO18
* Relay → IO8
* Buzzer → IO3
* Servo → IO10
* DHT11 → IO9

旁邊寫：**MCP Tool = 模組控制程式**

### 提問引導

* 「為什麼要用『工具（Tool）』這種抽象，而不是在雲端直接寫『GPIO18 = 1』？你們覺得差別在哪裡？」

---

## 第 9 頁：實驗一：開發板啟動與配網流程

### 投影片內容

**實驗一目標**

* 完成小智裝置配網
* 登入 Xizahi.me 並綁定裝置
* 可以與小智做基本對話

**步驟摘要**

1. 通電 → 藍燈閃爍進入配網模式
2. 手機/筆電連上 `Xiaozhi-xxxx`
3. 在設定頁輸入 Wi-Fi 帳密
4. 等待連線成功，觀察指示燈變化

### 講稿示意

「第一個實驗不碰程式，只做『配網與後臺綁定』。

請大家照講義步驟：

1. 先把電源接好，確認板子有上電，藍燈進入配網閃爍狀態；
2. 用手機或筆電連上 `Xiaozhi-xxxx` 這個 Wi-Fi；
3. 打開瀏覽器進入設定頁，輸入你們實驗桌對應的 Wi-Fi 帳號與密碼；
4. 按下儲存，看看指示燈是不是變成常亮或固定模式（依實際韌體說明）。

這一段成功，你的板子就真正『上線』了，之後才能跟雲端 AI 對話。」

### 板書建議

* 步驟：

  1. 上電 → 藍燈閃爍
  2. 連 `Xiaozhi-xxxx`
  3. 設定 Wi-Fi
  4. 測試 Ping / 對話

### 提問引導

* 「如果配網失敗，你會怎麼判斷問題在：Wi-Fi 密碼？路由器？還是板子本身？」

---

## 第 10 頁：Xizahi.me 後臺設定

### 投影片內容

**後臺操作重點**

* 建立帳號 / 登入平台
* 綁定小智裝置
* 配置角色（Configure Role）
* 開啟聲紋識別
* 查看歷史對話與裝置列表

### 講稿示意

「配好網之後，下一步是登入 Xizahi.me 後臺。

1. 先註冊或登入帳號；
2. 依照指示把你手上的那一塊小智裝置綁到你的帳號；
3. 在『配置角色』裡面幫它設定人設，例如：

   * 名字叫什麼？
   * 主要用途是什麼？（例如：實驗室助教、溫度提醒小管家）
4. 若有聲紋功能，可以錄自己的聲音，讓系統辨識「誰在說話」；
5. 最後看一下歷史對話記錄，確定雲端真的有收到你剛剛說的話。

這些設定會直接影響小智的回應風格和權限。」

### 板書建議

* 後臺：帳號 → 綁定 → 角色 → 聲紋 → 歷史記錄

### 提問引導

* 「如果你要幫小智設定一個『實驗室專用角色』，你會讓它擅長什麼？幫忙記實驗數據？提醒關電源？」

---

## 第 11 頁：程式開發環境（ESP-IDF / Arduino）

### 投影片內容

**ESP-IDF 流程（簡要）**

* `git clone` 專案
* `idf.py set-target esp32s3`
* `idf.py -p COMx build flash monitor`

**Arduino 流程（簡要）**

* 選擇開發板：ESP32-S3
* 安裝必要 Library（DHT、ArduinoJson…）
* 使用 Serial Monitor 測試

### 講稿示意

「在開發上，小智的原始專案是用 ESP-IDF 寫的，
但我們課堂上會以 Arduino 版本作為教學簡化。

ESP-IDF 的基本流程是：

1. 先 `set-target esp32s3`；
2. 再 `build`、`flash`、`monitor`。

Arduino 版則是比較直覺：

1. 選對開發板；
2. 安裝必要 Library；
3. 把程式寫好，按 Upload；
4. 打開 Serial Monitor 看輸出。

我們今天實驗的大部分程式，都會用 Arduino 風格，
方便大家之後延伸成自己的作品。」

### 板書建議

寫兩條：

* ESP-IDF：set-target → build → flash → monitor
* Arduino：Board → Library → Upload → Serial Monitor

### 提問引導

* 「你們之前比較常用哪一種？Arduino 還是原廠 SDK/IDF？覺得差別在哪裡？」

---

## 第 12 頁：Function Calling / MCP Tool 架構

### 投影片內容

**雲端端**

* 語音辨識 → LLM 解析語意
* 決定要呼叫的 Tool
* 回傳 JSON 指令

  * 例：`{"tool":"led","action":"on"}`

**裝置端**

* 解析 JSON
* 根據 `tool` / `action` 執行 MCP Tool
* 控制 GPIO / MQTT / LINE 等

### 講稿示意

「Function Calling 的概念是：
讓 AI 不只是『回答文字』，而是『幫我們呼叫功能』。

雲端這邊做的事情是：

1. 先把你的語音轉成文字；
2. 大模型讀懂你講的是『開燈』、還是『查天氣』；
3. 如果是『開燈』，就決定呼叫 `led` 這個 Tool，給出像這樣的 JSON：
   `{ "tool":"led", "action":"on" }`。

裝置端收到 JSON 後，只要：

1. 解析出 `tool` 和 `action`；
2. 對應到某個函式，例如 `handleLed("on")`；
3. 然後在裡面 `digitalWrite(LED_PIN, HIGH);`。

你們稍後看到的程式骨架，就是在做這件事。」

### 板書建議

寫：

* `tool = "led"`
* `action = "on"`
* → `handleLed()` → GPIO18 HIGH

### 提問引導

* 「如果未來我要加一個『play_music』的 Tool，要多做哪幾個步驟？雲端要改？裝置端也要改？」

---

## 第 13 頁：實驗二：語音 I/O 測試（INMP441 + MAX98357A）

### 投影片內容

**實驗二目標**

* 確認麥克風接線 OK
* 確認喇叭播放 OK
* 理解 I2S 在語音系統中的角色

**步驟摘要**

1. 依講義接好 INMP441 和 MAX98357A
2. 燒錄 I2S 播放範例程式
3. 測試上電提示音 / 測試語音播放
4. 討論 I2S 傳輸流程

### 講稿示意

「第二個實驗要確認『耳朵』和『嘴巴』都正常。

請各組照講義接好 INMP441 與 MAX98357A：

* 檢查 GND 有沒有共地；
* I2S 的三條線有沒有接對腳位。

然後我們燒錄一個簡單的 I2S 範例，
例如上電時播放一個『叮咚』或一段短音效。

只要你聽得到聲音，就代表：

* 板子上電正常；
* I2S 時序正確；
* 擴大機跟喇叭沒接錯。

之後我們再把這條線路接到語音助理裡。」

### 板書建議

* I2S：Clock + Data + LR
* 耳朵（Mic） & 嘴巴（Speaker）共用 I2S

### 提問引導

* 「如果你聽到的聲音是嗡嗡的雜訊，你會先檢查哪幾個點？」

---

## 第 14 頁：實驗三：語音控制 LED / Relay

### 投影片內容

**實驗三目標**

* 用語音指令控制 LED / Relay
* 實作一個簡單的 Function Calling → MCP Tool 流程

**任務示例**

* 「小智，開燈」→ LED 亮
* 「小智，關燈」→ LED 滅

### 講稿示意

「第三個實驗就是經典的『語音開關燈』。

流程可以想像成：

1. 你講『小智，開燈』；
2. 麥克風收音 → 板子送到雲端；
3. 雲端判斷要呼叫 LED Tool，回一個 `{ "tool":"led", "action":"on" }`；
4. 裝置端解析 JSON，呼叫 `handleLed("on")`，讓 GPIO18 拉高，LED 亮。

你們在程式裡看到的，就會像我們先前示範的骨架那樣，
只差在輸入來源不是 Serial，而是網路來的 JSON。

做完之後，你就完成一個『語音控制硬體』的最小實作。」

### 板書建議

畫小流程：

* 語音 → JSON → `handleLed(action)` → `digitalWrite(LED_PIN, x)`

### 提問引導

* 「如果我說的是『小智，把燈調暗一點』，
  你覺得 JSON 裡面除了 `tool`、`action` 還需要什麼欄位？」

---

## 第 15 頁：實驗四：語音 × IoT 擴充

### 投影片內容

**實驗四方向（分組或擇一）**

* A：語音觸發 DHT11 → MQTT 上報
* B：語音記帳 → LINE Notify 推播
* C：語音記帳 → 寫入 Google Sheet

**目標**

* 完成「語音指令 → 雲端服務」的一個小應用

### 講稿示意

「做到這裡，你們已經可以語音控制本地 LED / Relay。
接下來我們讓它『走出開發板』，連到外面的服務。

我提供三個方向給大家分組或擇一實作：

* A：問小智現在溫度，然後把 DHT11 讀到的數值用 MQTT 發佈出去；
* B：說『幫我記一筆 50 元午餐』，小智就用 LINE Notify 推播一則訊息到你的手機；
* C：同樣是記帳，但資料存到 Google Sheet，用來做簡單的雲端記帳本。

重點不是全部做完，而是你要體會：
『語音 → AI 理解 → Function Calling → IoT 平台』這一條完整的鏈。」

### 板書建議

寫：

* 語音 → AI → Tool → (MQTT / LINE / Sheet)

### 提問引導

* 「如果只能選一個做，你們比較想做哪一個？為什麼？」

---

## 第 16 頁：Deep Sleep 與喚醒機制（選講）

### 投影片內容

**Deep Sleep 概念**

* 降低功耗，延長電池續航
* Timer 喚醒：`esp_sleep_enable_timer_wakeup()`
* 外部喚醒：Ext0 / Ext1（按鍵、訊號）

**應用場景**

* 長時間待機的語音裝置
* 週期性監測（每 5 分鐘醒來一次）

### 講稿示意

「如果這台小智要靠電池供電，就不能一直滿功率運作。
Deep Sleep 就是 ESP32-S3 的省電模式，
在這個模式下，只有少數電路還在，功耗很低。

常見的喚醒方式有兩種：

1. Timer：例如設定 5 秒或 5 分鐘醒來一次；
2. 外部喚醒：例如按下按鍵、某腳位電平改變。

你們可以想像一個情境：
走廊上的感測器平常都在睡覺，
有人經過時被紅外線觸發，就喚醒，啟動語音提示或上報。

這在 IoT 和電池供電裝置裡非常重要。」

### 板書建議

* Deep Sleep → 功耗很低
* 喚醒：Timer / Ext0 / Ext1

### 提問引導

* 「如果你要設計一個靠電池供電、要撐一整學期的小智裝置，你會怎麼安排『醒著』和『睡覺』的比例？」

---

## 第 17 頁：實驗成果展示與常見錯誤

### 投影片內容

**可展示內容**

* 語音控制 LED / Relay 的 Demo 影片
* MQTT / LINE / Sheet 的畫面截圖

**常見錯誤**

* 接線錯誤（GND 未共地 / Vin 接反）
* BK-IO 對不上實際 GPIO
* Wi-Fi / Token 設定錯誤
* JSON 格式解析失敗

### 講稿示意

「等大家做到一段落，我會請幾組同學來示範一下成果，
例如：

* 用手機拍下你們『開燈/關燈』的過程；
* 或是在投影上秀出你們 MQTT 訂閱到的溫度、
  或 LINE/Sheet 被寫入的一筆資料。

在這個過程中，最常見的問題有幾個：

1. 接線錯誤，尤其是 GND 沒有共地、Vin/GND 接反；
2. BK-IO 編號和 Arduino 的 GPIO 號碼沒對齊；
3. Wi-Fi 設錯、Token 打錯；
4. JSON 少一個引號，結果整段解析失敗。

我們會一起看幾個『經典錯誤』，學會怎麼 debug。」

### 板書建議

* Debug checklist：

  1. 電源 / GND
  2. 腳位對應
  3. 網路 / Token
  4. JSON 格式

### 提問引導

* 「如果你的系統完全沒反應，你第一眼會先看哪裡？LED？Serial Monitor？還是後臺？」

---

## 第 18 頁：課後思考與延伸應用

### 投影片內容

**思考題**

1. 如何把小智變成「智慧家庭中樞」？
2. 長時間語音錄製的隱私與資安問題？
3. 還可以接哪些感測器或服務？

### 講稿示意

「最後我們來想一想，
如果不只是做一次作業，而是要把小智變成真正的產品，你會怎麼設計？

1. 在智慧家庭中，小智可以負責什麼？開關燈？開冷氣？提醒關瓦斯？
2. 如果它一直在聽你的聲音，你會擔心什麼？是不是需要離線喚醒詞？
3. 除了 DHT11，你還可以加哪些感測器？
   如門磁、紅外線、煙霧偵測、水浸偵測，甚至是攝影機。

這些都可以成為你們之後專題或畢業設計的起點。」

### 板書建議

* 延伸：

  * 智慧家庭
  * 安防提醒
  * 老人照護 / 寵物照護

### 提問引導

* 「如果要你把今天的小智延伸成一個『畢業專題』，你會選什麼主題？照護？家庭？教室管理？」

---

## 第 19 頁：作業與報告建議

### 投影片內容

**作業方向（範例）**

* 小組報告：

  * 「語音控制智慧插座設計」
  * 「語音記帳 × Google Sheet 可視化」
  * 「語音觸發的智慧實驗室警報系統」

**交付內容**

* 系統架構圖
* 功能流程圖
* 實作截圖 / Demo 影片
* 簡短書面說明

### 講稿示意

「如果要把這堂課的內容收斂成一個作業或小專題，
建議可以 2~3 人一組，選一個主題深入做。

交付內容大致包括：

1. 一張畫得清楚的系統架構圖；
2. 一張流程圖，說明從語音到動作的每一步；
3. 幾張實作截圖或 Demo 影片；
4. 一份 2~3 頁的簡短說明，寫明你們的功能、遇到的問題與解決方法。

這樣就可以很完整地展示你們不只是『會抄程式』，
而是真的懂『系統設計』。」

### 板書建議

* 作業：架構圖 + 流程圖 + 截圖 + 說明書

### 提問引導

* 「你們覺得在報告裡，哪一塊比較難寫？架構圖？還是『遇到問題與解法』？」

---

## 第 20 頁：Q&A

### 投影片內容

**Q & A**

* 歡迎提問
* 實作問題 / 延伸想法
* 專題可能題目討論

### 講稿示意

「最後這一頁就交給大家問問題。
可以問實作上的：接線、程式、後臺；
也可以問延伸應用：能不能結合某個感測器、某個雲端服務；
或者你已經想到一個專題方向，也可以拿出來一起討論。

沒有問題也沒關係，我會先點幾個常見的問題跟大家分享。」

### 板書建議

寫：

* Q&A
* 實作 / 延伸 / 專題

### 提問引導

* 「有沒有人願意分享一下，今天課後最想自己試試看的功能是什麼？」

---

